{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43317,
     "status": "ok",
     "timestamp": 1760323661988,
     "user": {
      "displayName": "í™©í˜¸ì„±",
      "userId": "05441793447983438923"
     },
     "user_tz": -540
    },
    "id": "GLXRM6qepp7P",
    "outputId": "6247159d-0f44-4dc9-b083-97a70af6375b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "DATA_PATH = \"\"\n",
    "df = pd.read_csv(DATA_PATH, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12544,
     "status": "ok",
     "timestamp": 1760323674539,
     "user": {
      "displayName": "í™©í˜¸ì„±",
      "userId": "05441793447983438923"
     },
     "user_tz": -540
    },
    "id": "yHA1XLwspjAe",
    "outputId": "806b2869-0bb2-45b8-bc06-5f78aace77e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda  | Torch: 2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "!pip install -q \"transformers>=4.40,<5\" \"peft>=0.11.0\" accelerate scikit-learn tqdm\n",
    "\n",
    "import os, re, gc, random, math, numpy as np, pandas as pd, torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from tqdm.notebook import tqdm\n",
    "from contextlib import nullcontext\n",
    "\n",
    "# ë©”ëª¨ë¦¬ íŒŒí¸í™” ì™„í™”\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# ì‹œë“œ/ë””ë°”ì´ìŠ¤\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device, \" | Torch:\", torch.__version__)\n",
    "\n",
    "# L100 ìµœì í™”: TF32 + (ê¸°ë³¸) BF16\n",
    "USE_BF16 = True\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "def autocast_ctx():\n",
    "    if not torch.cuda.is_available():\n",
    "        return nullcontext()\n",
    "    # BF16 ë¯¸ì§€ì›ì¼ ë•Œ ìë™ìœ¼ë¡œ FP16ìœ¼ë¡œ í´ë°±\n",
    "    try:\n",
    "        dtype = torch.bfloat16 if USE_BF16 else torch.float16\n",
    "        return torch.autocast(device_type=\"cuda\", dtype=dtype)\n",
    "    except TypeError:\n",
    "        # ë“œë¬¼ê²Œ í™˜ê²½ì—ì„œ BF16 íƒ€ì… ì§€ì›ì´ ë¶ˆì™„ì „í•  ìˆ˜ ìˆìŒ\n",
    "        return torch.autocast(device_type=\"cuda\", dtype=torch.float16)\n",
    "\n",
    "# í•˜ì´í¼(ì†ë„/ì„±ëŠ¥ íŠ¸ë ˆì´ë“œì˜¤í”„: â˜…í‘œëŠ” ì†ë„ì— í° ì˜í–¥)\n",
    "BASE_MODEL   = \"monologg/koelectra-base-v3-discriminator\"\n",
    "MAX_LEN      = 192             # â˜… 192~224 (ì¤„ìˆ˜ë¡ ë¹ ë¦„)\n",
    "BATCH_BAGS   = 8               # bag=ë¬¸ì„œ, ë°°ì¹˜ í¬ê¸°\n",
    "EPOCHS       = 3\n",
    "\n",
    "LR_ENCODER   = 2e-5\n",
    "LR_HEAD      = 2e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "USE_GC       = False           # â˜… Gradient Checkpointing í•´ì œ(ë¹ ë¦„, ë©”ëª¨ë¦¬ ì¶©ë¶„í•  ë•Œ)\n",
    "VAL_BATCH1   = True            # ê²€ì¦ ë°°ì¹˜=1ë¡œ OOM ë°©ì§€\n",
    "USE_COMPILE  = False           # torch.compile ì‹œ True (ì²« ìŠ¤í… ì˜¤ë²„í—¤ë“œ ìˆìŒ)\n",
    "\n",
    "# Hard-positive ìºì‹œ\n",
    "HARD_CACHE_TOPK = 2         # ë¬¸ì„œë³„ í•­ìƒ í¬í•¨í•  ìƒìœ„ ì˜ì‹¬ ë¬¸ë‹¨ ìˆ˜\n",
    "REFRESH_HARD_EVERY_EPOCH = True\n",
    "\n",
    "# MIL/ë¡œìŠ¤ ê°•í™”\n",
    "POOL_MODE   = \"lse\"         # 'attn'|'lse'|'max'|'mean'  (lseê°€ ì˜ˆë¦¬)\n",
    "LSE_TAU     = 12.0          # (ê¸°ì¡´ 10) ì˜ˆë¦¬í•¨ ì¡°ê¸ˆ â†‘\n",
    "BAG_AGG     = \"noisy_or\"    # 'linear' or 'noisy_or'  (ë¦¬ì½œâ†‘)\n",
    "INST_TOPK   = 2             # (ê¸°ì¡´ 1) ì–‘ì„± ë¬¸ì„œì—ì„œ 2ê°œ ë¬¸ë‹¨ì„ 1ë¡œ ë‹¹ê¹€\n",
    "INST_LAMBDA = 0.15          # (ê¸°ì¡´ 0.1) ë³´ì¡°ì†ì‹¤ ê°€ì¤‘ì¹˜ â†‘\n",
    "\n",
    "DIR = ''\n",
    "OUTPUT_DIR = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13392,
     "status": "ok",
     "timestamp": 1760323687934,
     "user": {
      "displayName": "í™©í˜¸ì„±",
      "userId": "05441793447983438923"
     },
     "user_tz": -540
    },
    "id": "t64VLBj-p0hD",
    "outputId": "ba768c3d-2f9d-453e-eeca-7cc5e2353846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ë²¨ë³„ ë¬¸ë‹¨ ê¸¸ì´ í¼ì„¼íƒ€ì¼\n",
      "              p35     p95\n",
      "generated                \n",
      "0          1057.0  6999.0\n",
      "1          1052.0  6873.3\n",
      "Train docs: 673411  | Valid docs: 74577\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# 1) ë°ì´í„° ë¡œë”© & ì „ì²˜ë¦¬\n",
    "# =========================================\n",
    "def minimal_preprocess(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[\\u4E00-\\u9FFF]', '', text)                   # í•œì ì œê±°\n",
    "    text = re.sub(r'<[^>]+>', '', text)                           # HTML íƒœê·¸ ì œê±°\n",
    "    text = re.sub(r'\\(\\s*[^\\wê°€-í£]*\\s*\\)', '', text)             # ë¹ˆ ê´„í˜¸ ì œê±°\n",
    "    text = re.sub(r'\\([^\\(\\)]{0,20}[\\?\\~]{1,3}[^\\(\\)]{0,20}\\)', '', text)  # ( ? ~ ? ) ì œê±°\n",
    "    text = re.sub(r'[.,]{3,}', '.', text)                         # ... â†’ .\n",
    "    text = re.sub(r'[()]{2,}', '', text)                          # ê´„í˜¸ ì”ì¬ ì •ë¦¬\n",
    "    text = re.sub(r',\\s*,+', ',', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)                              # ì¤‘ë³µ ê³µë°± ì œê±°\n",
    "    return text\n",
    "def split_paragraphs(text: str):\n",
    "    \"\"\"ë¹ˆ ì¤„ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ë‹¨ ë¶„í• \"\"\"\n",
    "        # ë¬¸ë‹¨ ê¸°ì¤€: ë‘ ì¤„ ê°œí–‰ ìš°ì„ \n",
    "    paragraphs = [p.strip() for p in text.split('\\n') if p.strip()]\n",
    "    # # ë§Œì•½ ë„ˆë¬´ ì ê²Œ ìª¼ê°œì¡Œìœ¼ë©´ í•œ ì¤„ ê°œí–‰ìœ¼ë¡œ ì¬ì‹œë„\n",
    "    if len(paragraphs) <= 1:\n",
    "        paragraphs = [p.strip() for p in text.split('\\n') if p.strip()]\n",
    "    return paragraphs\n",
    "# ë¬¸ë‹¨ ë¶„í•´\n",
    "def split_paragraphs(text: str):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    parts = [p.strip() for p in re.split(r'\\n\\s*', text) if p.strip()]\n",
    "    return parts if parts else [text.strip()]\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(DIR+\"train.csv\")\n",
    "\n",
    "#df[\"full_text\"] = df[\"full_text\"].apply(minimal_preprocess)\n",
    "# 1) ë¬¸ë‹¨ ê¸¸ì´(ë¬¸ì ìˆ˜) ê³„ì‚°\n",
    "df['char_len'] = df['full_text'].str.len()\n",
    "\n",
    "# 2) ë¼ë²¨(generated)ë³„ 35 % Â· 95 % í¼ì„¼íƒ€ì¼ ê³„ì‚°\n",
    "percentiles = (\n",
    "    df\n",
    "      .groupby('generated')['char_len']\n",
    "      .quantile([0.35, 0.95])        # ë‘ ì§€ì  í•œ ë²ˆì— êµ¬í•¨\n",
    "      .unstack(level=1)              # ë³´ê¸° í¸í•˜ê²Œ: index=ë¼ë²¨, columns=p35/p95\n",
    "      .rename(columns={0.35: 'p35', 0.95: 'p95'})\n",
    ")\n",
    "\n",
    "print(\"ë¼ë²¨ë³„ ë¬¸ë‹¨ ê¸¸ì´ í¼ì„¼íƒ€ì¼\")\n",
    "print(percentiles)\n",
    "# 3) ìœ„ ê¸°ì¤€ì„ ì´ìš©í•´ í•„í„°ë§\n",
    "mask = df.apply(\n",
    "    lambda r: percentiles.loc[r['generated'], 'p35'] <= r['char_len'] <= percentiles.loc[r['generated'], 'p95'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df1 = (\n",
    "    df[mask]\n",
    "      .reset_index(drop=True)\n",
    "      .drop(columns=['char_len'])   # ê¸¸ì´ ì»¬ëŸ¼ì´ í•„ìš” ì—†ìœ¼ë©´ ì œê±°\n",
    ")\n",
    "\n",
    "\n",
    "df1['paragraphs'] = df1['full_text'].apply(split_paragraphs)\n",
    "df1 = df1.drop(columns=['full_text'])\n",
    "train_df = df1.explode('paragraphs').rename(columns={'paragraphs':'full_text'}).reset_index(drop=True)\n",
    "assert set([\"title\",\"full_text\",\"generated\"]).issubset(train_df.columns), \"train.csv columns mismatch\"\n",
    "\n",
    "# title ê¸°ì¤€ ëˆ„ìˆ˜ ë°©ì§€ ë¶„í• \n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.1, random_state=SEED)\n",
    "tr_idx, va_idx = next(gss.split(train_df, groups=train_df[\"title\"]))\n",
    "tr_df = train_df.iloc[tr_idx].reset_index(drop=True)\n",
    "va_df = train_df.iloc[va_idx].reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"Train docs:\", len(tr_df), \" | Valid docs:\", len(va_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242,
     "referenced_widgets": [
      "5fb086391cd54177b966853861d66ab3",
      "1a02b9b0a6af42f5b0aec1ea441d2433",
      "88d205a09b524567b5f8b8cae8119ab5",
      "f2418ff22f4a49209711feb5705fea15",
      "6784a9a7ca404f8fb077e429f7c8e9a6",
      "715be56f4e2c4aca852b8f78e42e6a56",
      "20208490618a49a5bdbc8c8e64a739cb",
      "c78b9d4d30a84539af890280459aa443",
      "4cb49ab41b65476ea73a445bbb9e166e",
      "6c2029978ab048d19d1911d2fa40ecc3",
      "dc04aa7418d649f4ab85cd35330e5990",
      "b38122bff4cf468d86f23fda01d42ff8",
      "13a4edbca1e14ec99c9b0e5133cab8b0",
      "37881fee8596443ba0294b8ca312b4c7",
      "1de6ce3a6950418997b17e4b52efbf39",
      "5b6b6838482f433e800a928736df76f8",
      "126ecd9025b748c2995929de931ecf27",
      "ddb7ffe3d7eb4ed9b868a5ce14c78201",
      "575b2ec80e394b5a8ec2cc58a7a05e14",
      "857ef5272d444e6db46687cd0c11a728",
      "010f1d087f534ce891b3453f1cdae46e",
      "3d6f9f96919a4910932fb895e4bebb7f",
      "4b3de74bffbe4e82aa5120225e48e5ad",
      "b955b84c831d4f5a97dc13e627d9a03c",
      "26986f3147534bdfa2c59acc7be451b6",
      "0c24d097c2f0412b92f6f3647bd3db8a",
      "db412bc8dd574f72911669bf21596bc3",
      "256ba3d6c7ef4e12a1febc6746708c1b",
      "ea385a26b8a64929af50b7a015f5d240",
      "09668febcc4542c2bb44ba66d5d676cd",
      "7fbe86d7942d48bd8ab3062a4e35c449",
      "187c7c1978e64931acf06c4afdf30970",
      "2bab44a775b84c42baeeef5daa5f621d"
     ]
    },
    "executionInfo": {
     "elapsed": 11201,
     "status": "ok",
     "timestamp": 1760323699140,
     "user": {
      "displayName": "í™©í˜¸ì„±",
      "userId": "05441793447983438923"
     },
     "user_tz": -540
    },
    "id": "lXkbiUsQqIJz",
    "outputId": "3a53a04a-49dd-486c-89c8-997325e3d8ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb086391cd54177b966853861d66ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/61.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38122bff4cf468d86f23fda01d42ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3de74bffbe4e82aa5120225e48e5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35257,
     "status": "ok",
     "timestamp": 1760323734412,
     "user": {
      "displayName": "í™©í˜¸ì„±",
      "userId": "05441793447983438923"
     },
     "user_tz": -540
    },
    "id": "xSWPaCqZqKhi",
    "outputId": "e821a8c3-4fac-46a2-f6ab-486f3d8f9f64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_weight = 10.949021417037812\n"
     ]
    }
   ],
   "source": [
    "#Dataset & Collate (â˜…ì†ë„ í•µì‹¬: ë¬¸ë‹¨ ì„œë¸Œìƒ˜í”Œë§)\n",
    "\n",
    "# ë¶ˆê· í˜• ê°€ì¤‘ì¹˜(ë¬¸ì„œ ë‹¨ìœ„)\n",
    "num_pos = int(tr_df[\"generated\"].sum())\n",
    "num_neg = len(tr_df) - num_pos\n",
    "POS_WEIGHT = (num_neg / max(num_pos, 1))\n",
    "print(\"pos_weight =\", POS_WEIGHT)\n",
    "\n",
    "class MILDataset(Dataset):\n",
    "    def __init__(self, df, has_label=True):\n",
    "        self.docs = []\n",
    "        for _, r in df.iterrows():\n",
    "            paras = split_paragraphs(r[\"full_text\"]) if \"full_text\" in r else [r.get(\"paragraph_text\",\"\")]\n",
    "            item = {\"title\": r[\"title\"], \"paras\": paras}\n",
    "            if has_label:\n",
    "                item[\"label\"] = int(r[\"generated\"])\n",
    "            self.docs.append(item)\n",
    "    def __len__(self): return len(self.docs)\n",
    "    def __getitem__(self, idx): return self.docs[idx]\n",
    "\n",
    "tr_set = MILDataset(tr_df, has_label=True)\n",
    "va_set = MILDataset(va_df, has_label=True)\n",
    "\n",
    "# â˜…í›ˆë ¨ìš©: ë¬¸ì„œë‹¹ ë¬¸ë‹¨ Kê°œë§Œ ëœë¤ ìƒ˜í”Œ(í° ì†ë„ í–¥ìƒ)\n",
    "TRAIN_PARAS_PER_DOC = 12     # 6~12 ì¶”ì²œ. ëŠ˜ë¦´ìˆ˜ë¡ ëŠë¦¬ì§€ë§Œ ì„±ëŠ¥â†‘\n",
    "MAX_PARAS_CAP       = 64    # ì•„ì£¼ ê¸´ ë¬¸ì„œ ì•ˆì „ ìƒí•œ\n",
    "\n",
    "# ì–‘ì„± ê°€ì¤‘ì¹˜ ê°•í™”\n",
    "POS_WEIGHT  = (num_neg / max(num_pos, 1)) * 1.3   # ê¸°ì¡´ ë¹„ìœ¨ì— 1.3ë°° (ë¦¬ì½œ ì§€í–¥)\n",
    "USE_ASYM_FOCAL = True     # ë¹„ëŒ€ì¹­ í¬ì»¬ë¡œìŠ¤ on\n",
    "GAMMA_POS = 0.0           # ì–‘ì„± ìª½ì€ focusing ì•½í•˜ê²Œ\n",
    "GAMMA_NEG = 2.0           # ìŒì„± ìª½ì€ ê°•í•˜ê²Œ ì–µì œ\n",
    "EPS = 1e-8\n",
    "\n",
    "def collate_train_subsample(batch, tokenizer, max_len=256, k=TRAIN_PARAS_PER_DOC):\n",
    "    all_texts, bag_bounds, titles, labels = [], [], [], []\n",
    "    cursor = 0\n",
    "    for d in batch:\n",
    "        titles.append(d[\"title\"])\n",
    "        paras = d[\"paras\"] if d[\"paras\"] else [\"\"]\n",
    "\n",
    "        # ìƒí•œ-í›„ ì„œë¸Œìƒ˜í”Œ\n",
    "        if len(paras) > MAX_PARAS_CAP:\n",
    "            idx = np.random.choice(len(paras), MAX_PARAS_CAP, replace=False)\n",
    "            paras = [paras[i] for i in sorted(idx)]\n",
    "        if len(paras) > k:\n",
    "            idx = np.random.choice(len(paras), k, replace=False)\n",
    "            paras = [paras[i] for i in sorted(idx)]\n",
    "\n",
    "        start = cursor\n",
    "        all_texts.extend(paras)\n",
    "        cursor += len(paras); end = cursor\n",
    "        bag_bounds.append((start, end))\n",
    "        labels.append(d[\"label\"])\n",
    "    enc = tokenizer(all_texts, truncation=True, padding=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    return {\n",
    "        \"input_ids\": enc[\"input_ids\"],\n",
    "        \"attention_mask\": enc[\"attention_mask\"],\n",
    "        \"bag_bounds\": torch.tensor(bag_bounds, dtype=torch.long),\n",
    "        \"titles\": titles,\n",
    "        \"labels\": torch.tensor(labels, dtype=torch.float32)\n",
    "    }\n",
    "\n",
    "def collate_eval_full(batch, tokenizer, max_len=256):\n",
    "    # ê²€ì¦ì€ ì „ì²´ ë¬¸ë‹¨ ì‚¬ìš©(ì •í™•í‰ê°€)\n",
    "    all_texts, bag_bounds, titles, labels = [], [], [], []\n",
    "    cursor = 0\n",
    "    for d in batch:\n",
    "        titles.append(d[\"title\"])\n",
    "        paras = d[\"paras\"] if d[\"paras\"] else [\"\"]\n",
    "        start = cursor\n",
    "        all_texts.extend(paras)\n",
    "        cursor += len(paras); end = cursor\n",
    "        bag_bounds.append((start, end))\n",
    "        labels.append(d[\"label\"])\n",
    "    enc = tokenizer(all_texts, truncation=True, padding=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    return {\n",
    "        \"input_ids\": enc[\"input_ids\"],\n",
    "        \"attention_mask\": enc[\"attention_mask\"],\n",
    "        \"bag_bounds\": torch.tensor(bag_bounds, dtype=torch.long),\n",
    "        \"titles\": titles,\n",
    "        \"labels\": torch.tensor(labels, dtype=torch.float32)\n",
    "    }\n",
    "def collate_train_hardmix(batch, tokenizer, max_len=256, k=TRAIN_PARAS_PER_DOC):\n",
    "    all_texts, bag_bounds, titles, labels = [], [], [], []\n",
    "    cursor = 0\n",
    "    for d in batch:\n",
    "        titles.append(d[\"title\"])\n",
    "        paras = d[\"paras\"] if d[\"paras\"] else [\"\"]\n",
    "        # ìº¡\n",
    "        if len(paras) > MAX_PARAS_CAP:\n",
    "            idx = np.random.choice(len(paras), MAX_PARAS_CAP, replace=False)\n",
    "            paras = [paras[i] for i in sorted(idx)]\n",
    "\n",
    "        must = hard_cache.get(d[\"title\"], [])\n",
    "        remain_idx = [i for i in range(len(paras)) if i not in must]\n",
    "        need = max(0, min(k, len(paras)) - len(must))\n",
    "        extra = np.random.choice(remain_idx, size=need, replace=False).tolist() if need>0 else []\n",
    "        sel = sorted(must + extra)\n",
    "        paras = [paras[i] for i in sel]\n",
    "\n",
    "        start = cursor\n",
    "        all_texts.extend(paras)\n",
    "        cursor += len(paras); end = cursor\n",
    "        bag_bounds.append((start, end))\n",
    "        labels.append(d[\"label\"])\n",
    "\n",
    "    enc = tokenizer(all_texts, truncation=True, padding=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    return {\n",
    "        \"input_ids\": enc[\"input_ids\"],\n",
    "        \"attention_mask\": enc[\"attention_mask\"],\n",
    "        \"bag_bounds\": torch.tensor(bag_bounds, dtype=torch.long),\n",
    "        \"titles\": titles,\n",
    "        \"labels\": torch.tensor(labels, dtype=torch.float32)\n",
    "    }\n",
    "\n",
    "tr_loader = DataLoader(\n",
    "    tr_set, batch_size=BATCH_BAGS, shuffle=True,\n",
    "    collate_fn=lambda b: collate_train_hardmix(b, tokenizer, MAX_LEN),\n",
    "    num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2\n",
    ")\n",
    "va_loader = DataLoader(\n",
    "    va_set, batch_size=(1 if VAL_BATCH1 else BATCH_BAGS), shuffle=False,\n",
    "    collate_fn=lambda b: collate_eval_full(b, tokenizer, MAX_LEN),\n",
    "    num_workers=2, pin_memory=True, persistent_workers=True, prefetch_factor=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "630dfcc125de4b9fa5d6129a98f75156",
      "12714373cd794dac8e62730ca514d6b0",
      "64e9fa0051b841799423ef29767e3c76",
      "f4a0a29a8dea442f9dc9a39ade89d8bc",
      "9150bfad399547408be0f3eaf4951006",
      "fb18713c84394f8d829f72568e38fcc1",
      "9cd4cca81f5740059cc97430af6b192d",
      "b0ef3aefbe5048a38a7067b1d0249fef",
      "5919fb8339cf4810981c15a2dfb18f5c",
      "4e3da2c61c094d25b8ce42f28c483606",
      "e3b4878244674b04be6a82a7aa3ba231"
     ]
    },
    "executionInfo": {
     "elapsed": 16042,
     "status": "ok",
     "timestamp": 1760323750457,
     "user": {
      "displayName": "í™©í˜¸ì„±",
      "userId": "05441793447983438923"
     },
     "user_tz": -540
    },
    "id": "m0gq1mmLqVAu",
    "outputId": "c5091c2f-6334-4e2d-bb5d-8bae68b9f1eb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630dfcc125de4b9fa5d6129a98f75156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/452M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ok | encoder: PeftModelForFeatureExtraction\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ (LoRA + MILPooler + ë³´ì¡°ì†ì‹¤ + ê°€ì¤‘ì¹˜BCE)\n",
    "from transformers.models.electra import ElectraModel\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "class MILPooler(nn.Module):\n",
    "    \"\"\"Pooling ì„ íƒì§€: 'attn' | 'lse' | 'max' | 'mean'\"\"\"\n",
    "    def __init__(self, d, mode=\"lse\", r=128, lse_tau=10.0):\n",
    "        super().__init__()\n",
    "        self.mode = mode; self.tau = lse_tau\n",
    "        if mode == \"attn\":\n",
    "            self.W = nn.Linear(d, r)\n",
    "            self.u = nn.Linear(r, 1, bias=False)\n",
    "    def forward(self, H):  # H: [n_i, d]\n",
    "        if self.mode == \"mean\":\n",
    "            z = H.mean(dim=0)\n",
    "            alpha = torch.full((H.size(0),), 1.0/H.size(0), device=H.device)\n",
    "            return z, alpha\n",
    "        if self.mode == \"max\":\n",
    "            idx = torch.argmax(H.norm(dim=1))\n",
    "            z = H[idx]\n",
    "            alpha = torch.zeros(H.size(0), device=H.device); alpha[idx] = 1.0\n",
    "            return z, alpha\n",
    "        if self.mode == \"lse\":\n",
    "            e = H.norm(dim=1) * self.tau           # Ï„â†‘ â‡’ maxì— ê°€ê¹Œì›Œì§\n",
    "            alpha = torch.softmax(e, dim=0)\n",
    "            z = torch.sum(alpha.unsqueeze(-1) * H, dim=0)\n",
    "            return z, alpha\n",
    "        # attention\n",
    "        A = torch.tanh(self.W(H))\n",
    "        e = self.u(A).squeeze(-1)\n",
    "        alpha = torch.softmax(e, dim=0)\n",
    "        z = torch.sum(alpha.unsqueeze(-1) * H, dim=0)\n",
    "        return z, alpha\n",
    "\n",
    "def instance_aux_loss(s_logits, alpha, y, k=1):\n",
    "    \"\"\"ë¬¸ë‹¨ í™•ë¥  0.5ë¡œ ëª°ë¦¼ ë°©ì§€: ìŒì„±ì€ ì „ì²´â†“, ì–‘ì„±ì€ top-kë§Œ â†‘\"\"\"\n",
    "    if y < 0.5:\n",
    "        target = torch.zeros_like(s_logits)\n",
    "        return nn.functional.binary_cross_entropy_with_logits(s_logits, target)\n",
    "    else:\n",
    "        k = min(k, s_logits.size(0))\n",
    "        topk_idx = torch.topk(alpha, k=k, dim=0).indices\n",
    "        target = torch.zeros_like(s_logits); target[topk_idx] = 1.0\n",
    "        return nn.functional.binary_cross_entropy_with_logits(s_logits[topk_idx], target[topk_idx])\n",
    "\n",
    "class AttentionMILModel(nn.Module):\n",
    "    def __init__(self, encoder: nn.Module, attn_r=128, pos_weight=1.0,\n",
    "                 pool_mode=\"lse\", lse_tau=10.0, inst_aux_lambda=0.1, inst_aux_k=1):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        if USE_GC and hasattr(self.encoder, \"gradient_checkpointing_enable\"):\n",
    "            self.encoder.gradient_checkpointing_enable()\n",
    "        if hasattr(self.encoder.config, \"use_cache\"):\n",
    "            self.encoder.config.use_cache = False\n",
    "        d = self.encoder.config.hidden_size\n",
    "        self.instance_head = nn.Linear(d, 1)\n",
    "        self.pool = MILPooler(d, mode=pool_mode, r=attn_r, lse_tau=lse_tau)\n",
    "        self.bag_head = nn.Linear(d, 1)\n",
    "        # pos_weight(ë¶ˆê· í˜• ë³´ì •) ë“±ë¡\n",
    "        self.register_buffer(\"pos_weight\", torch.tensor(float(pos_weight)))\n",
    "        # ë¬¸ë‹¨ ë³´ì¡° ì†ì‹¤ ì„¤ì •\n",
    "        self.inst_aux_lambda = inst_aux_lambda\n",
    "        self.inst_aux_k = inst_aux_k\n",
    "\n",
    "    def encode_instances(self, input_ids, attention_mask, need_instance_logits=True):\n",
    "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        H = out.last_hidden_state[:, 0, :]                     # [N, d]\n",
    "        s = self.instance_head(H).squeeze(-1) if need_instance_logits else None\n",
    "        return H, s\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, bag_bounds, labels=None,\n",
    "                return_instance=True, return_alphas=False, **_):\n",
    "        H_all, s_all = self.encode_instances(input_ids, attention_mask, need_instance_logits=return_instance)\n",
    "        bag_logits, alphas_all = [], ([] if return_alphas else None)\n",
    "\n",
    "        inst_reg = 0.0\n",
    "        for bi, (start, end) in enumerate(bag_bounds.tolist()):\n",
    "            H = H_all[start:end]\n",
    "            z, alpha = self.pool(H)\n",
    "            S = self.bag_head(z).squeeze(-1)\n",
    "            bag_logits.append(S)\n",
    "            if return_alphas:\n",
    "                alphas_all.append(alpha)\n",
    "            if return_instance and labels is not None:\n",
    "                s_i = s_all[start:end]\n",
    "                inst_reg = inst_reg + instance_aux_loss(s_i, alpha, labels[bi], k=self.inst_aux_k)\n",
    "\n",
    "        bag_logits = torch.stack(bag_logits, dim=0)           # [B]\n",
    "        out = {\"bag_logits\": bag_logits}\n",
    "        if return_instance: out[\"instance_logits\"] = s_all\n",
    "        if return_alphas:   out[\"alphas\"] = alphas_all\n",
    "\n",
    "        if labels is not None:\n",
    "            bce = nn.functional.binary_cross_entropy_with_logits(\n",
    "                bag_logits, labels, pos_weight=self.pos_weight\n",
    "            )\n",
    "            # Î» * (bag í‰ê·  ë³´ì¡°ì†ì‹¤)\n",
    "            loss = bce + self.inst_aux_lambda * (inst_reg / len(bag_bounds))\n",
    "            out[\"loss\"] = loss\n",
    "        return out\n",
    "\n",
    "# Electra encoder + LoRA(FeatureExtraction)\n",
    "base_encoder = ElectraModel.from_pretrained(BASE_MODEL)\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8, lora_alpha=16, lora_dropout=0.1,\n",
    "    target_modules=[\"query\",\"value\"],  # í•„ìš”ì‹œ \"key\",\"dense\" ì¶”ê°€\n",
    "    task_type=\"FEATURE_EXTRACTION\"     # ì¤‘ìš”: ë¶„ë¥˜ í—¤ë“œê°€ ì•„ë‹Œ ì„ë² ë”© ì¶”ì¶œìš©\n",
    ")\n",
    "encoder_peft = get_peft_model(base_encoder, lora_cfg)\n",
    "\n",
    "model = AttentionMILModel(\n",
    "    encoder=encoder_peft,\n",
    "    attn_r=128,\n",
    "    pos_weight=POS_WEIGHT,\n",
    "    pool_mode=POOL_MODE,     # 'lse'ê°€ attnë³´ë‹¤ ì˜ˆë¦¬(ì¤‘ê°„ê°’ ì™„í™”)\n",
    "    lse_tau=LSE_TAU,\n",
    "    inst_aux_lambda=INST_LAMBDA, # 0.05~0.2 ì¶”ì²œ ë²”ìœ„\n",
    "    inst_aux_k=INST_TOPK,\n",
    ").to(device)\n",
    "\n",
    "if USE_COMPILE and hasattr(torch, \"compile\"):\n",
    "    model = torch.compile(model)\n",
    "\n",
    "print(\"model ok | encoder:\", type(model.encoder).__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1760323750585,
     "user": {
      "displayName": "í™©í˜¸ì„±",
      "userId": "05441793447983438923"
     },
     "user_tz": -540
    },
    "id": "mh0cQK-KqWey",
    "outputId": "6868c2b8-8fd7-4aaa-f85b-b89c47321df6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3138417607.py:26: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(not USE_BF16))\n"
     ]
    }
   ],
   "source": [
    "# ì˜µí‹°ë§ˆ/ìŠ¤ì¼€ì¤„ëŸ¬ & ì•ˆì „í˜¸ì¶œ\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "enc_params, head_params = [], []\n",
    "for n,p in model.named_parameters():\n",
    "    if any(k in n for k in [\"instance_head\",\"pool\",\"bag_head\"]):\n",
    "        head_params.append(p)\n",
    "    else:\n",
    "        enc_params.append(p)\n",
    "\n",
    "optimizer = AdamW([\n",
    "    {\"params\": enc_params, \"lr\": LR_ENCODER},\n",
    "    {\"params\": head_params, \"lr\": LR_HEAD},\n",
    "], weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "num_training_steps = EPOCHS * len(tr_loader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=max(1, int(0.1*num_training_steps)),   # ì›Œë°ì—…â†‘ (MIL ì•ˆì •í™”)\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# BF16ì´ë©´ GradScaler ë¶ˆí•„ìš”\n",
    "from torch.cuda.amp import GradScaler\n",
    "scaler = GradScaler(enabled=(not USE_BF16))\n",
    "\n",
    "def safe_forward(model, batch, *, train=True, return_instance=True, return_alphas=False):\n",
    "    assert model.__class__.__name__ == \"AttentionMILModel\"\n",
    "    return model(\n",
    "        input_ids      = batch[\"input_ids\"],\n",
    "        attention_mask = batch[\"attention_mask\"],\n",
    "        bag_bounds     = batch[\"bag_bounds\"],\n",
    "        labels         = (batch[\"labels\"] if train else None),\n",
    "        return_instance= return_instance,\n",
    "        return_alphas  = return_alphas,\n",
    "    )\n",
    "\n",
    "def _gpu_mem():\n",
    "    if not torch.cuda.is_available(): return \"CPU\"\n",
    "    a = torch.cuda.memory_allocated() / (1024**2)\n",
    "    r = torch.cuda.memory_reserved() / (1024**2)\n",
    "    return f\"{a:.0f}/{r:.0f}MB\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VnCDfdTG5aFK"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "hard_cache = defaultdict(list)\n",
    "\n",
    "@torch.no_grad()\n",
    "def refresh_hard_cache_fast(\n",
    "    model,\n",
    "    dataset,\n",
    "    tokenizer,\n",
    "    max_len_cache=160,     # ìºì‹œ ì „ìš© max_len (í•™ìŠµìš©ë³´ë‹¤ ë” ì§§ê²Œ)\n",
    "    topk=2,                # í•­ìƒ í¬í•¨í•  ì˜ì‹¬ ë¬¸ë‹¨ ìˆ˜\n",
    "    sample_k=64,           # ë¬¸ì„œë‹¹ ìºì‹œ ê³„ì‚°ì— ì‚¬ìš©í•  ìµœëŒ€ ë¬¸ë‹¨ ìˆ˜ (ë¶€ë¶„ ìƒ˜í”Œ)\n",
    "    pbar=True\n",
    "):\n",
    "    \"\"\"\n",
    "    ê° ë¬¸ì„œì—ì„œ 'ì˜ì‹¬ ì ìˆ˜ = alpha * sigmoid(s_i)' ê¸°ì¤€ ìƒìœ„ topk ë¬¸ë‹¨ ì¸ë±ìŠ¤ë¥¼ ìºì‹œì— ì €ì¥.\n",
    "    - ë§¤ìš° ê¸´ ë¬¸ì„œëŠ” sample_kê°œë§Œ ëœë¤ìœ¼ë¡œ ë½‘ì•„ ë¹ ë¥´ê²Œ ì ìˆ˜ ì‚°ì¶œ(ì†ë„ ë³´ì¥)\n",
    "    - ì§„í–‰ë¥  ë°”ê°€ í‘œì‹œë¨\n",
    "    \"\"\"\n",
    "    hard_cache.clear()\n",
    "    model.eval()\n",
    "\n",
    "    it = dataset.docs\n",
    "    if pbar:\n",
    "        it = tqdm(it, total=len(dataset), desc=\"build hard-cache\", ncols=120)\n",
    "\n",
    "    for doc in it:\n",
    "        title = doc[\"title\"]\n",
    "        paras = doc[\"paras\"] if doc[\"paras\"] else [\"\"]\n",
    "\n",
    "        # 1) ê¸¸ë©´ ë¶€ë¶„ ìƒ˜í”Œ (ì›ë³¸ ì¸ë±ìŠ¤ ê¸°ì–µ)\n",
    "        if len(paras) > sample_k:\n",
    "            sel_idx = np.sort(np.random.choice(len(paras), sample_k, replace=False))\n",
    "            sel_paras = [paras[i] for i in sel_idx]\n",
    "        else:\n",
    "            sel_idx = np.arange(len(paras))\n",
    "            sel_paras = paras\n",
    "\n",
    "        # 2) í† í°í™” (ìºì‹œ ì „ìš©ìœ¼ë¡œ ë” ì§§ì€ max_len)\n",
    "        enc = tokenizer(\n",
    "            sel_paras, truncation=True, padding=True,\n",
    "            max_length=max_len_cache, return_tensors=\"pt\"\n",
    "        )\n",
    "        batch = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "        # 3) í•œ ë²ˆì˜ ì¸í¼ëŸ°ìŠ¤ (í•´ë‹¹ ë¬¸ì„œë§Œ bagìœ¼ë¡œ ë¬¶ìŒ)\n",
    "        with autocast_ctx():\n",
    "            out = model(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                bag_bounds=torch.tensor([(0, len(sel_paras))], dtype=torch.long, device=device),\n",
    "                labels=None, return_instance=True, return_alphas=True\n",
    "            )\n",
    "\n",
    "        # 4) ì ìˆ˜ ê³„ì‚°: alpha * sigmoid(s_i)\n",
    "        s = torch.sigmoid(out[\"instance_logits\"].float()).detach().cpu().numpy()\n",
    "        a = out[\"alphas\"][0].detach().cpu().numpy()\n",
    "        score = a * s\n",
    "\n",
    "        # 5) ìƒìœ„ topk (ë¶€ë¶„ ìƒ˜í”Œ ì¸ë±ìŠ¤ë¥¼ ì›ë³¸ ì¸ë±ìŠ¤ë¡œ ë˜ëŒë¦¼)\n",
    "        k = max(1, min(topk, len(sel_idx)))\n",
    "        local_top = np.argsort(-score)[:k]\n",
    "        global_top = sel_idx[local_top]\n",
    "        hard_cache[title] = np.sort(global_top).tolist()\n",
    "\n",
    "        # 6) ë©”ëª¨ë¦¬ ì²­ì†Œ(ê¸´ ë¬¸ì„œ ëŒ€ë¹„)\n",
    "        del enc, batch, out\n",
    "        torch.cuda.empty_cache()\n",
    "        try:\n",
    "            torch.cuda.ipc_collect()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    model.train()\n",
    "    print(f\"[hard-cache] built for {len(hard_cache)} titles \"\n",
    "          f\"(topk={topk}, sample_k={sample_k}, max_len_cache={max_len_cache})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oD7vEpXXq1OT"
   },
   "outputs": [],
   "source": [
    "#ê²½ëŸ‰ê²€ì¦\n",
    "@torch.no_grad()\n",
    "def evaluate_bag_light(model, loader):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    with torch.inference_mode():\n",
    "        for batch in loader:\n",
    "            batch = {k:(v.to(device) if torch.is_tensor(v) else v) for k,v in batch.items()}\n",
    "            with autocast_ctx():\n",
    "                out = safe_forward(model, batch, train=False, return_instance=False, return_alphas=False)\n",
    "                logits = out[\"bag_logits\"].float()              # âœ… ì•ˆì „ ìºìŠ¤íŒ…\n",
    "                probs  = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            ys.extend(batch[\"labels\"].cpu().numpy()); ps.extend(probs)\n",
    "            del out, batch, logits, probs\n",
    "            torch.cuda.empty_cache()\n",
    "            try: torch.cuda.ipc_collect()\n",
    "            except: pass\n",
    "    ys = np.array(ys); ps = np.array(ps).reshape(-1)\n",
    "    return {\"AUC\": roc_auc_score(ys, ps), \"PR_AUC\": average_precision_score(ys, ps)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jymsKnfqqX1a"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµ ë£¨í”„ (BF16/FP16 ìë™, ì„œë¸Œìƒ˜í”Œë§ìœ¼ë¡œ ë¹ ë¥´ê²Œ)\n",
    "best_auc, global_step = -1.0, 0\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "   # ğŸ”¸ ì—í­ ì‹œì‘ ì‹œ ìºì‹œ ìƒˆë¡œê³ ì¹¨ (ì¤‘ìš”!)\n",
    "    refresh_hard_cache_fast(\n",
    "    model, tr_set, tokenizer,\n",
    "    max_len_cache=160,   # ìºì‹œ ì „ìš©ìœ¼ë¡œ ì§§ê²Œ\n",
    "    topk=HARD_CACHE_TOPK,\n",
    "    sample_k=64,         # ë¬¸ì„œë‹¹ ìºì‹œ ê³„ì‚°ì— ìµœëŒ€ 64ë¬¸ë‹¨ë§Œ ì‚¬ìš©\n",
    "    pbar=True            # ì§„í–‰ë¥  í‘œì‹œ\n",
    ")\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    pbar = tqdm(\n",
    "      total=len(tr_loader),\n",
    "      desc=f\"Epoch {ep}/{EPOCHS}\",\n",
    "      ncols=140,                # âœ… ë„“ì´ í™•ëŒ€\n",
    "      leave=True,\n",
    "      bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]\",\n",
    "      colour=\"#4CAF50\"          # âœ… ì´ˆë¡ìƒ‰\n",
    "      )\n",
    "\n",
    "    for step, batch in enumerate(tr_loader, start=1):\n",
    "        batch = {k:(v.to(device) if torch.is_tensor(v) else v) for k,v in batch.items()}\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast_ctx():\n",
    "            out  = safe_forward(model, batch, train=True, return_instance=True, return_alphas=False)\n",
    "            loss = out[\"loss\"]\n",
    "\n",
    "        if USE_BF16:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer); scaler.update()\n",
    "\n",
    "        scheduler.step()\n",
    "        global_step += 1\n",
    "        running = loss.item() if step==1 else 0.9*running + 0.1*loss.item()\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\", \"avg\": f\"{running:.4f}\",\n",
    "                          \"lr\": f\"{scheduler.get_last_lr()[-1]:.2e}\", \"mem\": _gpu_mem()})\n",
    "        pbar.update(1)\n",
    "        del out, batch, loss\n",
    "    pbar.close()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    try: torch.cuda.ipc_collect()\n",
    "    except: pass\n",
    "\n",
    "    m = evaluate_bag_light(model, va_loader)\n",
    "    print(f\"[Epoch {ep}] val AUC={m['AUC']:.4f} | PR-AUC={m['PR_AUC']:.4f}\")\n",
    "    if m[\"AUC\"] > best_auc:\n",
    "        best_auc = m[\"AUC\"]\n",
    "        torch.save(model.state_dict(), OUTPUT_DIR+\"attnmil_lora_best6.pt\")\n",
    "        ckpt = {\n",
    "          \"model\": model.state_dict(),\n",
    "          \"optimizer\": optimizer.state_dict(),\n",
    "          \"scheduler\": scheduler.state_dict(),\n",
    "          \"scaler\": scaler.state_dict(),\n",
    "          \"epoch\": ep,\n",
    "          \"best_auc\": best_auc,\n",
    "          \"lora_cfg\": lora_cfg.to_dict(),        # ì•ˆì „í•˜ê²Œ ê°™ì´ ì €ì¥\n",
    "          \"base_model\": BASE_MODEL,\n",
    "        }\n",
    "        torch.save(ckpt, OUTPUT_DIR+\"attnmil_full_ckpt6.pt\")\n",
    "        print(\"  â†³ best saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "4beac2786c534b7b9da2d9654da144cb",
      "012cfb8d1f634acd89cdd2f87aa9ded2",
      "ae21dbe076074abca5e82f1febb16acc",
      "532c980c5584428da040bbc4d226814a",
      "b9a3e92c21ef4fef9cd313e5ae5228a6",
      "6e03e959b613429795e2a0e81b426c29",
      "3b59598e6c4f45298a89b69961adb4bd",
      "689505c479214cf8952f83fd5ee6d252",
      "36af2f80b72a4b5fbd4f36e3313b71cc",
      "4166df3eb12649798609036b9cafd762",
      "f18a67cc8c164d61a7bf67dc3c1578e5"
     ]
    },
    "executionInfo": {
     "elapsed": 1365151,
     "status": "ok",
     "timestamp": 1760325115848,
     "user": {
      "displayName": "í™©í˜¸ì„±",
      "userId": "05441793447983438923"
     },
     "user_tz": -540
    },
    "id": "W3JMLwCHrkm7",
    "outputId": "9b465840-394d-4cc6-91a3-908e1b3cd962"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4beac2786c534b7b9da2d9654da144cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/452M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Optimized Temperature T = 0.0385\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def collect_bag_logits(model, loader):\n",
    "    model.eval()\n",
    "    logits, labels = [], []\n",
    "    with torch.inference_mode():\n",
    "        for batch in loader:\n",
    "            batch = {k:(v.to(device) if torch.is_tensor(v) else v) for k,v in batch.items()}\n",
    "            with autocast_ctx():\n",
    "                out = safe_forward(model, batch, train=False, return_instance=False, return_alphas=False)\n",
    "                logits.append(out[\"bag_logits\"].detach().cpu())\n",
    "                labels.append(batch[\"labels\"].detach().cpu())\n",
    "    return torch.cat(logits), torch.cat(labels)\n",
    "\n",
    "val_logits, val_labels = collect_bag_logits(model, va_loader)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "log_T = torch.nn.Parameter(torch.tensor(0.0, device=device))\n",
    "opt_T = torch.optim.Adam([log_T], lr=0.05)\n",
    "val_logits_d, val_labels_d = val_logits.to(device), val_labels.to(device)\n",
    "\n",
    "best_T, best_loss = None, float(\"inf\")\n",
    "for _ in range(400):\n",
    "    opt_T.zero_grad(set_to_none=True)\n",
    "    T = F.softplus(log_T) + 1e-6\n",
    "    loss = F.binary_cross_entropy_with_logits(val_logits_d / T, val_labels_d)\n",
    "    loss.backward()\n",
    "    opt_T.step()\n",
    "    if loss.item() < best_loss:\n",
    "        best_loss, best_T = loss.item(), float(T.item())\n",
    "print(f\"âœ… Optimized Temperature T = {best_T:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19002,
     "status": "ok",
     "timestamp": 1760325134846,
     "user": {
      "displayName": "í™©í˜¸ì„±",
      "userId": "05441793447983438923"
     },
     "user_tz": -540
    },
    "id": "eskDOkScuyuj",
    "outputId": "58022b24-3ff7-42b1-c166-3cd1a6b6a24b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: (1962, 2) â†’ submission_fast_strong6.csv\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(DIR+\"test.csv\")\n",
    "assert set([\"ID\",\"title\",\"paragraph_index\",\"paragraph_text\"]).issubset(test_df.columns)\n",
    "test_df[\"paragraph_text\"] = test_df[\"paragraph_text\"].astype(str).fillna(\"\")\n",
    "test_df = test_df.sort_values([\"title\",\"paragraph_index\"]).reset_index(drop=True)\n",
    "\n",
    "class TestParagraphDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.groups = []\n",
    "        for title, g in df.groupby(\"title\"):\n",
    "            self.groups.append({\"title\": title, \"paras\": g[\"paragraph_text\"].tolist(), \"index\": g.index.tolist()})\n",
    "    def __len__(self): return len(self.groups)\n",
    "    def __getitem__(self, idx): return self.groups[idx]\n",
    "\n",
    "def collate_test(batch, tokenizer, max_len=256):\n",
    "    all_texts, bag_bounds, titles, indices = [], [], [], []\n",
    "    cursor = 0\n",
    "    for d in batch:\n",
    "        titles.append(d[\"title\"]); indices.append(d[\"index\"])\n",
    "        paras = d[\"paras\"] if d[\"paras\"] else [\"\"]\n",
    "        start = cursor\n",
    "        all_texts.extend(paras)\n",
    "        cursor += len(paras); end = cursor\n",
    "        bag_bounds.append((start, end))\n",
    "    enc = tokenizer(all_texts, truncation=True, padding=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    return {\"input_ids\": enc[\"input_ids\"], \"attention_mask\": enc[\"attention_mask\"],\n",
    "            \"bag_bounds\": torch.tensor(bag_bounds, dtype=torch.long),\n",
    "            \"titles\": titles, \"indices\": indices}\n",
    "\n",
    "te_set = TestParagraphDataset(test_df)\n",
    "te_loader = DataLoader(te_set, batch_size=1, shuffle=False,\n",
    "                       collate_fn=lambda b: collate_test(b, tokenizer, MAX_LEN))\n",
    "\n",
    "# ë™ì¼ êµ¬ì¡°ë¡œ best ë¡œë“œ\n",
    "best_encoder = ElectraModel.from_pretrained(BASE_MODEL)\n",
    "best_encoder = get_peft_model(best_encoder, lora_cfg)\n",
    "best_model = AttentionMILModel(\n",
    "    encoder=best_encoder, attn_r=128, pos_weight=POS_WEIGHT,\n",
    "    pool_mode=\"lse\", lse_tau=10.0, inst_aux_lambda=0.1, inst_aux_k=1\n",
    ").to(device)\n",
    "best_model.load_state_dict(torch.load(OUTPUT_DIR+\"attnmil_lora_best6.pt\", map_location=device))\n",
    "best_model.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer(model, loader, T: float):\n",
    "    paragraph_probs = np.zeros(len(test_df), dtype=float)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in loader:\n",
    "            batch = {k: (v.to(device) if torch.is_tensor(v) else v) for k, v in batch.items()}\n",
    "            with autocast_ctx():\n",
    "                out = model(\n",
    "                    input_ids=batch[\"input_ids\"],\n",
    "                    attention_mask=batch[\"attention_mask\"],\n",
    "                    bag_bounds=batch[\"bag_bounds\"],\n",
    "                    labels=None,\n",
    "                    return_instance=True,\n",
    "                    return_alphas=False,\n",
    "                )\n",
    "\n",
    "                # âœ… ë¬¸ë‹¨ ë¡œì§“ì„ float32ë¡œ ìºìŠ¤íŒ… í›„ sigmoid\n",
    "                inst_logits = out[\"instance_logits\"].float()               # <-- í•µì‹¬ 1\n",
    "                p_all = torch.sigmoid(inst_logits).detach().cpu().numpy() # <-- í•µì‹¬ 2\n",
    "\n",
    "                # (ë¬¸ì„œ í™•ë¥  ë³´ê³ ìš©ì´ í•„ìš”í•˜ë©´)\n",
    "                # doc_prob = torch.sigmoid(out[\"bag_logits\"].float() / T).item()\n",
    "\n",
    "                (start, end) = batch[\"bag_bounds\"][0].tolist()\n",
    "                idxs = batch[\"indices\"][0]\n",
    "                paragraph_probs[idxs] = p_all[start:end]\n",
    "\n",
    "            del out, batch, inst_logits, p_all\n",
    "            torch.cuda.empty_cache()\n",
    "            try:\n",
    "                torch.cuda.ipc_collect()\n",
    "            except:\n",
    "                pass\n",
    "    return paragraph_probs\n",
    "\n",
    "paragraph_probs = infer(best_model, te_loader, T=best_T)\n",
    "\n",
    "submission = pd.DataFrame({\"ID\": test_df[\"ID\"], \"generated\": paragraph_probs})\n",
    "# ë°©ë²• 1) ë³´ì¡° ì»¬ëŸ¼ ë§Œë“¤ì–´ ì •ë ¬\n",
    "submission[\"id_num\"] = submission[\"ID\"].str.extract(r\"(\\d+)\").astype(int)\n",
    "submission = submission.sort_values(\"id_num\").drop(columns=\"id_num\").reset_index(drop=True)\n",
    "submission.to_csv(OUTPUT_DIR+\"submission_fast_strong6.csv\", index=False)\n",
    "print(\"Saved:\", submission.shape, \"â†’ submission_fast_strong6.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PUzTdJXqa3y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wg9jbDWX1bl0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fm4-l_8UHJnv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNqlSMKdQVxOsYPFUFHx1gw",
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "010f1d087f534ce891b3453f1cdae46e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "012cfb8d1f634acd89cdd2f87aa9ded2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e03e959b613429795e2a0e81b426c29",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3b59598e6c4f45298a89b69961adb4bd",
      "value": "model.safetensors:â€‡100%"
     }
    },
    "09668febcc4542c2bb44ba66d5d676cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "0c24d097c2f0412b92f6f3647bd3db8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_187c7c1978e64931acf06c4afdf30970",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2bab44a775b84c42baeeef5daa5f621d",
      "value": "â€‡263k/?â€‡[00:00&lt;00:00,â€‡16.0MB/s]"
     }
    },
    "126ecd9025b748c2995929de931ecf27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12714373cd794dac8e62730ca514d6b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb18713c84394f8d829f72568e38fcc1",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9cd4cca81f5740059cc97430af6b192d",
      "value": "pytorch_model.bin:â€‡100%"
     }
    },
    "13a4edbca1e14ec99c9b0e5133cab8b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_126ecd9025b748c2995929de931ecf27",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ddb7ffe3d7eb4ed9b868a5ce14c78201",
      "value": "config.json:â€‡100%"
     }
    },
    "187c7c1978e64931acf06c4afdf30970": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a02b9b0a6af42f5b0aec1ea441d2433": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_715be56f4e2c4aca852b8f78e42e6a56",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_20208490618a49a5bdbc8c8e64a739cb",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "1de6ce3a6950418997b17e4b52efbf39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_010f1d087f534ce891b3453f1cdae46e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3d6f9f96919a4910932fb895e4bebb7f",
      "value": "â€‡467/467â€‡[00:00&lt;00:00,â€‡59.9kB/s]"
     }
    },
    "20208490618a49a5bdbc8c8e64a739cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "256ba3d6c7ef4e12a1febc6746708c1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26986f3147534bdfa2c59acc7be451b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09668febcc4542c2bb44ba66d5d676cd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7fbe86d7942d48bd8ab3062a4e35c449",
      "value": 1
     }
    },
    "2bab44a775b84c42baeeef5daa5f621d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "36af2f80b72a4b5fbd4f36e3313b71cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "37881fee8596443ba0294b8ca312b4c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_575b2ec80e394b5a8ec2cc58a7a05e14",
      "max": 467,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_857ef5272d444e6db46687cd0c11a728",
      "value": 467
     }
    },
    "3b59598e6c4f45298a89b69961adb4bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d6f9f96919a4910932fb895e4bebb7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4166df3eb12649798609036b9cafd762": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b3de74bffbe4e82aa5120225e48e5ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b955b84c831d4f5a97dc13e627d9a03c",
       "IPY_MODEL_26986f3147534bdfa2c59acc7be451b6",
       "IPY_MODEL_0c24d097c2f0412b92f6f3647bd3db8a"
      ],
      "layout": "IPY_MODEL_db412bc8dd574f72911669bf21596bc3"
     }
    },
    "4beac2786c534b7b9da2d9654da144cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_012cfb8d1f634acd89cdd2f87aa9ded2",
       "IPY_MODEL_ae21dbe076074abca5e82f1febb16acc",
       "IPY_MODEL_532c980c5584428da040bbc4d226814a"
      ],
      "layout": "IPY_MODEL_b9a3e92c21ef4fef9cd313e5ae5228a6"
     }
    },
    "4cb49ab41b65476ea73a445bbb9e166e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4e3da2c61c094d25b8ce42f28c483606": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "532c980c5584428da040bbc4d226814a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4166df3eb12649798609036b9cafd762",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f18a67cc8c164d61a7bf67dc3c1578e5",
      "value": "â€‡452M/452Mâ€‡[00:06&lt;00:00,â€‡44.8MB/s]"
     }
    },
    "575b2ec80e394b5a8ec2cc58a7a05e14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5919fb8339cf4810981c15a2dfb18f5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5b6b6838482f433e800a928736df76f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fb086391cd54177b966853861d66ab3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a02b9b0a6af42f5b0aec1ea441d2433",
       "IPY_MODEL_88d205a09b524567b5f8b8cae8119ab5",
       "IPY_MODEL_f2418ff22f4a49209711feb5705fea15"
      ],
      "layout": "IPY_MODEL_6784a9a7ca404f8fb077e429f7c8e9a6"
     }
    },
    "630dfcc125de4b9fa5d6129a98f75156": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_12714373cd794dac8e62730ca514d6b0",
       "IPY_MODEL_64e9fa0051b841799423ef29767e3c76",
       "IPY_MODEL_f4a0a29a8dea442f9dc9a39ade89d8bc"
      ],
      "layout": "IPY_MODEL_9150bfad399547408be0f3eaf4951006"
     }
    },
    "64e9fa0051b841799423ef29767e3c76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0ef3aefbe5048a38a7067b1d0249fef",
      "max": 451741507,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5919fb8339cf4810981c15a2dfb18f5c",
      "value": 451741507
     }
    },
    "6784a9a7ca404f8fb077e429f7c8e9a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "689505c479214cf8952f83fd5ee6d252": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c2029978ab048d19d1911d2fa40ecc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e03e959b613429795e2a0e81b426c29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "715be56f4e2c4aca852b8f78e42e6a56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fbe86d7942d48bd8ab3062a4e35c449": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "857ef5272d444e6db46687cd0c11a728": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88d205a09b524567b5f8b8cae8119ab5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c78b9d4d30a84539af890280459aa443",
      "max": 61,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4cb49ab41b65476ea73a445bbb9e166e",
      "value": 61
     }
    },
    "9150bfad399547408be0f3eaf4951006": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cd4cca81f5740059cc97430af6b192d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae21dbe076074abca5e82f1febb16acc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_689505c479214cf8952f83fd5ee6d252",
      "max": 451716860,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_36af2f80b72a4b5fbd4f36e3313b71cc",
      "value": 451716860
     }
    },
    "b0ef3aefbe5048a38a7067b1d0249fef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b38122bff4cf468d86f23fda01d42ff8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_13a4edbca1e14ec99c9b0e5133cab8b0",
       "IPY_MODEL_37881fee8596443ba0294b8ca312b4c7",
       "IPY_MODEL_1de6ce3a6950418997b17e4b52efbf39"
      ],
      "layout": "IPY_MODEL_5b6b6838482f433e800a928736df76f8"
     }
    },
    "b955b84c831d4f5a97dc13e627d9a03c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_256ba3d6c7ef4e12a1febc6746708c1b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ea385a26b8a64929af50b7a015f5d240",
      "value": "vocab.txt:â€‡"
     }
    },
    "b9a3e92c21ef4fef9cd313e5ae5228a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c78b9d4d30a84539af890280459aa443": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db412bc8dd574f72911669bf21596bc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc04aa7418d649f4ab85cd35330e5990": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ddb7ffe3d7eb4ed9b868a5ce14c78201": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3b4878244674b04be6a82a7aa3ba231": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea385a26b8a64929af50b7a015f5d240": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f18a67cc8c164d61a7bf67dc3c1578e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2418ff22f4a49209711feb5705fea15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c2029978ab048d19d1911d2fa40ecc3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_dc04aa7418d649f4ab85cd35330e5990",
      "value": "â€‡61.0/61.0â€‡[00:00&lt;00:00,â€‡7.60kB/s]"
     }
    },
    "f4a0a29a8dea442f9dc9a39ade89d8bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e3da2c61c094d25b8ce42f28c483606",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e3b4878244674b04be6a82a7aa3ba231",
      "value": "â€‡452M/452Mâ€‡[00:07&lt;00:00,â€‡52.3MB/s]"
     }
    },
    "fb18713c84394f8d829f72568e38fcc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
