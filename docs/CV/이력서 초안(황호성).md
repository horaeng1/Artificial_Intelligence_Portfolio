# 황호성 | AI NLP 엔지니어 (신입/주니어)

[github.com/?](https://github.com/yourhandle) ·  hhs6228@gmail.com · 010-0000-0000 

  

## 한 줄 소개


**문제정의 중심형 NLP 엔지니어**입니다. 데이터로 문제를 **정확히 정의**하고, 코드를 빠르게 파악해 **원인→해결**까지 이끌어 냅니다. 불완전한 라벨이나 복잡한 코드 기반에서도 **핵심 신호를 찾아 성능을 올린 경험**이 있습니다.

## 핵심역량

-  **약한 감독(Weak Supervision)·MIL 설계**: 문단 로짓 → 문서 로짓 **LogSumExp(τ)** 풀링, **Instance 보조 손실(top-k)**, **Hard-Positive Subsampling**으로 신호 증폭

-  **디버깅·안정화**: 안전 인덱싱, AMP·gradient clipping으로 학습 안정화

-  **재현 가능한 실험 설계**: LoRA·스케줄러/워밍업·클리핑 등 효율 학습 파이프라인 표준화

-  **커뮤니케이션**: 문제-가설-실험-결과를 수치·근거로 보고서화(README)

  

## 기술스택

-  **Language/Frameworks**: Python, PyTorch, Hugging Face Transformers/Datasets, scikit-learn

-  **NLP**: Tokenization, KoELECTRA/KoBERT, MIL/Attention Pooling, LoRA/Fine-tuning

-  **MLOps/실험관리**: Colab, Weights & Biases, GitHub, CUDA

-  **Data**: Pandas, NumPy, 데이터 전처리/불균형 대응(Sampling/Calibration)

-  **Etc**: Linux, Shell, Markdown, Git

  

## 대표 프로젝트

**생성형 AI vs 인간 문단 판별 (DACON, 2025)**

-  **Public ROC-AUC 0.8639 / Private 0.8693**

- KoELECTRA 기반 인코더 + **LogSumExp(τ)** 풀링, **Instance 보조 손실(top-k)**, **Hard-Positive Subsampling** 적용

- 약라벨 환경에서 핵심 문단의 노출 빈도 및 로짓 분리를 개선하여 **결정 경계의 예리함(Sharper)** 확보

- Repo: https://github.com/? (README/학습노트 정리)

  

## 교육·학력

-  **멋쟁이사자처럼 AI NLP 부트캠프** (수료 예정, 2025) — KoELECTRA 파인튜닝, MIL, LoRA 실습 중심

-  **OO대학교 컴퓨터공학과** (학점 **4.1/4.5**) — 확률/선형대수/최적화·프로그래밍 기초

  

## 추가 링크

- 포트폴리오 개요: (노션/깃허브 페이지) — 프로젝트 요약·회고
